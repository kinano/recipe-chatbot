# Develop an LLM as a judge

I want you to help me develop an LLM as a judge module using Python.

Name the module kf_develop_judge.py

Please create a new module in the hw3 scripts folder and create scaffolding for the LLM as a judge with the following requirements in mind:

1. the judge must have a system prompt that indicates its role: recipes expert and a dietary restriction specialist.
2. The judge will examine the provided user queries and the corresponding outputs generated by the application and determine whether the output meets or violates the dietary restrictions in the user query. It must take into account both the query and the response to issue its judgement.
3. For every recipe, the judge will output a JSON payload as follows

```
# Format of the input (CSV)
query,dietary_restriction,response,label,error,trace_id,query_id

query: is the user input requesting a recipe. It includes the dietary restrictions and constraints.
dietary_restriction: the dietary restriction of the user (extracted from the query).
response: the output generated by the application.
label: the label assigned by a human annotator for the same trace.
error: error describing the failure.
trace_id: unique identifier for the trace.
query_id: identifier of the query.



# Format of the output
The judge will create a new csv file in the data folder using the following naming convention:
llm_as_judge_eval_run_{TIMESTAMP}.csv
where TIMESTAMP = current timestamp in YYYY-MM-DD-HH-MM-SS format.

For every evaluated row, the judge will create a new dictionary and add the following fields:
{
  "llm_judge_label": "pass or fail",
  "reason": "text",
  "confidence": "low or medium or high based on the quality of the output for the provided query and the dietary restriction",
  "trace_id": "copied from the value provided in the input file",
  "query_id: "copied from the value provided in the input file"
}

When the judge is done with evaluating all rows in the file, the judge will write the extended rows to the new CSV file llm_as_judge_eval_run_{TIMESTAMP}.csv
```

4. The generated python script should allow the callers to pass in the path to a CSV file to run the LLM judge against.
